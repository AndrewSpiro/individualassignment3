{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "import en_core_web_lg\n",
    "import pandas as pd\n",
    "\n",
    "from funcs.feature_transformation_funcs import *\n",
    "import pylcs\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spiro\\AppData\\Local\\Temp\\ipykernel_3860\\2332377633.py:2: DtypeWarning: Columns (6,9,10,11,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  full_preprocessed_data = pd.read_csv(\"data/preprocessed data/full preprocessed data.csv\")\n"
     ]
    }
   ],
   "source": [
    "full_attributes = pd.read_csv(\"data/preprocessed data/full attributes as cols.csv\")\n",
    "full_preprocessed_data = pd.read_csv(\"data/preprocessed data/full preprocessed data.csv\")\n",
    "test_attributes = pd.read_csv(\"data/preprocessed data/test attributes as cols.csv\")\n",
    "test_preprocessed_data = pd.read_csv(\"data/preprocessed data/test preprocessed data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'product_uid_left', 'product_title', 'search_term',\n",
       "       'relevance', 'product_description', 'search_term_stem',\n",
       "       'product_title_stem', 'product_description_stem',\n",
       "       'product_info_stemmed', 'product_info', 'product_uid_right', 'name',\n",
       "       'value', 'all_values', 'search_term_and_all_attributes', 'product_uid',\n",
       "       'Assembled Measurement (DxWxH)', 'Product Measurement (LxWxD)',\n",
       "       'Product Measurement (DxWxH)', 'title_and_assembled_measurement',\n",
       "       'title_and_measurement_LWD', 'title_and_measurement_DWH',\n",
       "       'title_and_assembled_measurement_stem',\n",
       "       'title_and_measurement_LWD_stem', 'title_and_measurement_DWH_stem',\n",
       "       'Color Family', 'Color/Finish', 'Color Family Stem',\n",
       "       'Color/Finish Stem', 'title_and_color', 'title_and_color_fam',\n",
       "       'title_and_color_stem', 'title_and_color_fam_stem'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preprocessed_data.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86261, 24)\n",
      "(166693, 35)\n",
      "(14, 24)\n",
      "(400, 35)\n"
     ]
    }
   ],
   "source": [
    "print(full_attributes.shape)\n",
    "print(full_preprocessed_data.shape)\n",
    "print(test_attributes.shape)\n",
    "print(test_preprocessed_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_query_legth(df_all):\n",
    "# \t# CALCULATE THE LENGTH OF THE SEARCH QUERY\n",
    "# \tdf_all['len_of_query'] = df_all['search_term_stem'].map(lambda x:0 if type(x) != str else len(x.split())).astype(np.int64)\n",
    " \n",
    "# \treturn df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = loaded_data\n",
    "# calc_query_legth(data)\n",
    "# count_common_words(data)\n",
    "# calc_spacy_title_query(data)\n",
    "# print('starting long spacy')\n",
    "# calc_spacy_long(data)\n",
    "# unstemmed_all, stemmed_all, counts_only, spacy_only = finalise_and_export(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_subsequence(df_all, attributes):\n",
    "    \n",
    "    combined = pd.concat((df_all, attributes), axis = 1)\n",
    "    \n",
    "    df_all['lcs_title'] = combined.apply(lambda x: pylcs.lcs_sequence_length(str(x['search_term_stem']), str(x['product_title_stem'])), axis = 1)\n",
    "    df_all['lcs_brand'] = combined.apply(lambda x: pylcs.lcs_sequence_length(str(x['search_term_stem']), str(x['MFG Brand Name'])), axis = 1)\n",
    "    df_all['lcs_title_string'] = combined.apply(lambda x: pylcs.lcs_string_length(str(x['search_term_stem']), str(x['product_title_stem'])), axis = 1)\n",
    "    df_all['lcs_brand_string'] = df_all.apply(lambda x: pylcs.lcs_string_length(str(x['search_term_stem']), str(x['MFG Brand Name'])), axis = 1)\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_str_common_word(str1, str2):\n",
    "\tif type(str1) == str and type(str2) == str:\n",
    "\t\treturn sum(int(str2.find(word)>=0) for word in set(str1.split()))\n",
    "\telse:\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_str_common_letters(str1, str2):\n",
    "\tif type(str1) == str and type(str2) == str:\n",
    "\t\treturn sum(len(word) if word in str2 else 0 for word in set(str1.split()))\n",
    "\telse:\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The ratio of number of letters in the intersection of unique words in the query and title, description, and attributes yielded 3 more\n",
    " features (6). The same thing but with number of words instead of letters yielded another 3 (9)'''\n",
    " \n",
    "def count_unique_common_words(df_all):\n",
    "    df_all['unique_word_in_title_stemmed'] = df_all['product_info_stemmed'].map(lambda x:unique_str_common_word(x.split('\\t')[0],x.split('\\t')[1]) if type(x) == str else 0)\n",
    "    df_all['unique_word_in_description_stemmed'] = df_all['product_info_stemmed'].map(lambda x:unique_str_common_word(x.split('\\t')[0],x.split('\\t')[2]) if type(x) == str else 0)\n",
    "\n",
    "    # uncomment to include unstemmed\n",
    "    # df_all['unique_word_in_title'] = df_all['product_info'].map(lambda x:unique_str_common_word(x.split('\\t')[0],x.split('\\t')[1]) if type(x) == str else 0)\n",
    "    # df_all['unique_word_in_description'] = df_all['product_info'].map(lambda x:unique_str_common_word(x.split('\\t')[0],x.split('\\t')[2]) if type(x) == str else 0)\n",
    "# \n",
    "    # CODE BLOCK 4: COMPUTING NEW COUNT FEATURES\n",
    "    # ADDING ATTRIBUTES - COUNT OF PRODUCT ATTRIBUTES IN THE SEARCH TERM\n",
    "    df_all['unique_word_in_attributes'] = df_all['search_term_and_all_attributes'].map(lambda x:unique_str_common_word(x.split('\\t')[0],x.split('\\t')[2]) if type(x)==str else 0)\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = count_unique_common_words(test_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_common_letter(df_all):\n",
    "\n",
    "    df_all['unique_letter_in_title_stemmed'] = df_all['product_info_stemmed'].map(lambda x:unique_str_common_letters(x.split('\\t')[0],x.split('\\t')[1]) if type(x) == str else 0)\n",
    "    df_all['unique_letter_in_description_stemmed'] = df_all['product_info_stemmed'].map(lambda x:unique_str_common_letters(x.split('\\t')[0],x.split('\\t')[2]) if type(x) == str else 0)\n",
    "\n",
    "    # uncomment to include unstemmed\n",
    "    # df_all['unique_word_in_title'] = df_all['product_info'].map(lambda x:unique_str_common_letters(x.split('\\t')[0],x.split('\\t')[1]) if type(x) == str else 0)\n",
    "    # df_all['unique_word_in_description'] = df_all['product_info'].map(lambda x:unique_str_common_letters(x.split('\\t')[0],x.split('\\t')[2]) if type(x) == str else 0)\n",
    "\n",
    "    # CODE BLOCK 4: COMPUTING NEW COUNT FEATURES\n",
    "    # ADDING ATTRIBUTES - COUNT OF PRODUCT ATTRIBUTES IN THE SEARCH TERM\n",
    "    df_all['unique_letter_in_attributes'] = df_all['search_term_and_all_attributes'].map(lambda x:unique_str_common_letters(x.split('\\t')[0],x.split('\\t')[2]) if type(x)==str else 0)\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = count_unique_common_letter(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_frequency_ratios(df_all):\n",
    "    df_all['len_search_term_stem_word'] = df_all['search_term_stem'].map(lambda x: len(x.split()))\n",
    "    df_all['len_search_term_stem_letter'] = df_all['search_term_stem'].map(lambda x: len(x))\n",
    "    \n",
    "    df_all['search_title_uniqe_words'] = df_all['unique_word_in_title_stemmed']/ df_all['len_search_term_stem_word']\n",
    "    df_all['search_description_uniqe_words'] = df_all['unique_word_in_description_stemmed']/ df_all['len_search_term_stem_word']\n",
    "    df_all['search_attributes_uniqe_words'] = df_all['unique_word_in_attributes']/ df_all['len_search_term_stem_word']\n",
    "    \n",
    "    df_all['search_title_uniqe_letters'] = df_all['unique_letter_in_title_stemmed']/ df_all['len_search_term_stem_letter']\n",
    "    df_all['search_description_uniqe_letters'] = df_all['unique_letter_in_description_stemmed']/ df_all['len_search_term_stem_letter']\n",
    "    df_all['search_attributes_uniqe_letters'] = df_all['unique_letter_in_attributes']/ df_all['len_search_term_stem_letter']\n",
    "    \n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_frequency_ratios(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "geeks =pd.DataFrame({\n",
    "    'query':['Ben','Steve', 'Data Scientists'],\n",
    "    'description':[\n",
    "        'Ben studies about computer in Computer Lab.',\n",
    "        'Steve teaches at Brown University.',\n",
    "        'Data Scientists work on large datasets.'\n",
    "        ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 2, 'cat': 3, 'deer': 1, 'bull': 0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,1,1,1],[2,2,2,2]])\n",
    "b = dict({\n",
    "    'dog':2,\n",
    "    'cat':3,\n",
    "    'deer':1,\n",
    "    'bull':0\n",
    "})\n",
    "c = sorted(b, key = lambda x: b[x])\n",
    "d = [len(word) for word in c]\n",
    "e = a*d\n",
    "e\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333333, 0.        , 0.33333333, 0.        , 0.66666667,\n",
       "        0.        , 0.        , 0.33333333, 0.33333333, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.4472136 , 0.        , 0.4472136 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.4472136 ,\n",
       "        0.4472136 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.40824829, 0.40824829, 0.        , 0.        , 0.40824829,\n",
       "        0.40824829, 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40824829]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tfidf_score(df_all):\n",
    "        \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_scores = tfidf_vectorizer.fit_transform(df_all['description'])\n",
    "\n",
    "    sorted_vocab = sorted(tfidf_vectorizer.vocabulary_, key = lambda x: tfidf_vectorizer.vocabulary_)\n",
    "    df_all['word_len_weighted_scores'] = pd.DataFrame(tfidf_scores * sorted_vocab)\n",
    "    \n",
    "    df_all['weighted_tfidf'] = df_all.apply(lambda x: sum[x['word_len_weighted_scores'][word] for word in x['search_term']], axis = 1)\n",
    "    \n",
    "    df_all.drop('word_len_weighted_scores')\n",
    "    \n",
    "    return df_all   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ben': 2, 'studies': 13, 'about': 0, 'computer': 4, 'in': 7, 'lab': 8, 'steve': 12, 'teaches': 14, 'at': 1, 'brown': 3, 'university': 15, 'data': 5, 'scientists': 11, 'work': 16, 'on': 10, 'large': 9, 'datasets': 6}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "as3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
